---
title: "Stanを使った変数選択"
author: Y.Nakahashi
date: 2018-04-20
output: html_notebook
---

### 背景
Stanを使ってモデリングをしている時に不満を感じる点として、変数選択が難しいということが挙げられます。もともと私自身は、例えばStepwiseやLassoなどを用いた"機械的な"変数選択があまり好きではない[^1]のですが、それでも分析を効率的に進める上でそれらの手法に頼りたくなることがあります。

そういったときに*glm*を用いているのであれば*step*関数により容易に変数選択が可能なのですが、Stanではそうもいきません。何か良い方法はないかと探していたところ、[StanのGithubレポジトリ](https://github.com/stan-dev)に`{projpred}`というそれっぽいlibraryを見つけたので、紹介がてら変数の選択精度を実験してみます[^2]。

[^1]:探索的な分析の時はともかく、変数の機械的な取捨選択は「モデリングじゃない！」という気分になってしまいます

[^2]:他にも良い手法はあると思います。例えば松浦さんのアヒル本では、回帰係数の事前分布を二重指数分布とすることで不要な説明変数を削る"Bayesian Lasso"という手法が紹介されています

### データ準備
#### ライブラリの読み込み
今回の分析では`{rstan}`の代わりに`{rstanarm}`というlibraryを使用します。`{rstanarm}`はRの*glm*と同じようなシンタックスのままでモデルをベイズ化することが可能で、例えば`{rstanarm}`のvignetteでは以下のようなスニペットが紹介されています(一部改変あり)[^3]。 

```{r}
library(rstanarm)
data("womensrole", package = "HSAUR3")
womensrole$total <- womensrole$agree + womensrole$disagree

womensrole_bglm_1 <- stan_glm(cbind(agree, disagree) ~ education + gender,
                              data = womensrole,
                              family = binomial(link = "logit"), 
                              prior = student_t(df = 7), 
                              prior_intercept = student_t(df = 7),
                              chains = 4, cores = 1, seed = 123)
womensrole_bglm_1
```

数字の意味は一旦置いておきますが、今回はこちらのlibraryを使用しながら進めていきます。
続いて他のlibraryを読み込みます。この辺りはvignetteそのままです。

[^3]:Gelmanのarm::bayesglmとの関係はよくわかりません。一応、dependencyではないようですが。

```{r}
library(projpred)
library(ggplot2)
library(bayesplot)
theme_set(theme_bw())
options(mc.cores = parallel::detectCores())
```

#### シミュレーションデータの作成
実験を進めるにあたりシミュレーションデータを作成します。もちろんlibraryに付属のデータセットを使っても良いのですが、そのまま同じことをするのも面白くないので以下のように複数のデータを作成して結果を比較してみましょう：

 1. 説明変数の数が少なく(20)、連続変数のみ
 1. 説明変数の数が多く(100)、連続変数のみ
 1. 説明変数の数が少なく(20)、ダミー変数を含む
 1. 説明変数の数が多く(100)、ダミー変数を含む

見てわかる通りで、説明変数の数とダミー変数の有無によって4パターンを用意します。なぜこのパターンにしたかというと、単純にvignetteを見ていて連続変数ばかりだなと思ったのと、サンプルデータの説明変数の数が20ぐらいで、これなら機械的な選択に頼らなくても自力でどうにかできそうだな、と思ったためです。

各パターンについて特にひねりもなくデータを作成します。なお真のモデルは1と2、3と4で同一のものとしました。したがって2と4の状況は、1と3それぞれに比べて「不要なデータのみが追加された状態」での変数選択という状況になります。

以下のように各パラメータを設定します。

```{r}
set.seed(1)
N    <- 100 # number of observations
xn_1 <- 20  # number of variables for pattern 1
xn_2 <- 100 # number of variables for pattern 2

b1 <- 0.5 # regression coefficient of X[, 1]
b2 <- 0.8 # regression coefficient of X[, 2]

var_e <- 1 # residual variance
```

パターン1 & 2について、まず乱数によりXを生成し、そのうちの2列を使ってYを作成します。またその2列を含む20列および全列を各パターンの説明変数とします。

```{r}
X <- matrix(rnorm(N * xn_2, 0, 1), nrow = N, ncol = xn_2)
Y <- 1.0 + X[, 1] * b1 + X[, 2] * b2 + rnorm(N, 0, var_e)

X1 <- X[, 1:xn_1]
X2 <- X[, 1:xn_2]

dat1 <- data.frame("Y" = Y, "X" = I(X1))
dat2 <- data.frame("Y" = Y, "X" = I(X2))
```

データセットを作成する際にX1を*I*で囲って渡すことでX1全体を"X"として再定義できます。すると以下のようなformulaが実行可能になります。

```{r}
lm(Y ~ X, dat1)
```

もちろんそのまま渡して`.`で指定するのでも構いません。

```{r}
tmp <- data.frame("Y" = Y, "X" = X1)
lm(Y ~ ., tmp)
```

続いてパターン3 & 4についても基本的に同じ流れでデータを作成しますが、一部にダミー変数を含めます。

```{r}
Z <- matrix(rnorm(N * xn_2, 0, 1), nrow = N, ncol = xn_2)
Z[, seq(1, 100, 10)] <- if_else(Z[, seq(1, 100, 10)] > 0, 1, 0)
Y <- 1.0 + Z[, 1] * b1 + Z[, 2] * b2 + rnorm(N, 0, var_e)

X3 <- Z[, 1:xn_1]
X4 <- Z[, 1:xn_2]

dat3 <- data.frame("Y" = Y, "X" = I(X3))
dat4 <- data.frame("Y" = Y, "X" = I(X4))
```


### フィッティング
#### stan_glmによるフィッティング
では、これらのデータを用いてフィッティングをしてみましょう。スクリプトは以下のようになります：

```{r}
n <- N
D <- xn_1
p0 <- 5 # prior guess for the number of relevant variables

# scale for tau (notice that stan_glm will automatically scale this by sigma)
tau0 <- p0 / (D-p0) * 1/sqrt(n) 
prior_coeff <- hs(global_scale = tau0, slab_scale = 1) # regularized horseshoe prior
fit1 <- stan_glm(Y ~ X, family = gaussian(), data = dat1, prior = prior_coeff,
                seed = 777, chains = 4, iter = 2000) 
```

```{r}
D <- xn_2
p0 <- 5
tau0 <- p0/(D-p0) * 1/sqrt(n) 
prior_coeff <- hs(global_scale = tau0, slab_scale = 1)
fit2 <- stan_glm(Y ~ X, family = gaussian(), data = dat2, prior = prior_coeff,
                seed = 777, chains = 4, iter = 2000) 
```

```{r}
D <- xn_1
p0 <- 5
tau0 <- p0 / (D-p0) * 1/sqrt(n) 
prior_coeff <- hs(global_scale = tau0, slab_scale = 1)
fit3 <- stan_glm(Y ~ X, family = gaussian(), data = dat3, prior = prior_coeff,
                seed = 777, chains = 4, iter = 2000) 
```

```{r}
D <- xn_2
p0 <- 5
tau0 <- p0 / (D-p0) * 1/sqrt(n) 
prior_coeff <- hs(global_scale = tau0, slab_scale = 1)
fit4 <- stan_glm(Y ~ X, family = gaussian(), data = dat4, prior = prior_coeff,
                seed = 777, chains = 4, iter = 2000) 
```

### 結果の確認
無事にフィッティングが終わったのでまずは結果を確認しましょう。`fit1`オブジェクトには多くの情報が格納されていますが、以下のようにパラメータの分布を確認します。

```{r}
fit1$stan_summary
```

この結果を見るとX1とX2で設定通りの値が得られているようですね。

ではここから`{projpred}`による変数選択に取り掛かりましょう。スクリプトは以下のようになります：

```{r}
sel1 <- varsel(fit1, method = 'forward')
sel1$varsel$vind # variables ordered as they enter during the search
```

おおっ！ちゃんと1列目と2列目が選ばれていますね！下記のプロットを見ても、3番目以降の変数はモデルの精度に対して寄与していないことがわかると思います[^4]。なおここで`elpd`は*expected log predictive density*を指しますが、ちょっと情報量規準辺りの話はうかつに解説できないのでvignetteを引用するに留めておきます。

>The loo method for stanreg objects provides an interface to the loo package for approximate leaveone-out
cross-validation (LOO). The LOO Information Criterion (LOOIC) has the same purpose as
the Akaike Information Criterion (AIC) that is used by frequentists. Both are intended to estimate
the expected log predictive density (ELPD) for a new dataset.


```{r}
# plot predictive performance on training data 
# png("../Image/projpred_sel1_varsel.png")
varsel_plot(sel1, stats=c('elpd', 'rmse'))
# dev.off()
```


各パラメータの分布についても見てみましょう。上位5個に選ばれた説明変数に限定してプロットしてみます。

```{r}
# Visualise the three most relevant variables in the full model
png("../Image/projpred_sel1_mcmcarea.png")
mcmc_areas(as.matrix(sel1), 
           pars = names(sel1$varsel$vind[1:5])) + 
   coord_cartesian(xlim = c(-2, 2))
dev.off()
```

効果のなかった変数は0を中心に集中して分布していることがわかります。

残りの各パターンについても同様に見ていきますが、個別に確認するのは面倒なので一度にまとめてしまします。

```{r}
sel2 <- varsel(fit2, method = 'forward')
sel3 <- varsel(fit3, method = 'forward')
sel4 <- varsel(fit4, method = 'forward')

sel2$varsel$vind
sel3$varsel$vind
sel4$varsel$vind
```

むむ。。。

いずれのパターンでも2列目はちゃんと選ばれていますが、パターン3と4では1列目が選ばれていませんね。
プロットも見てみましょう。

```{r}
# png("../Image/projpred_sel2_varsel.png")
varsel_plot(sel2, stats=c('elpd', 'rmse'))
# dev.off()
# png("../Image/projpred_sel3_varsel.png")
varsel_plot(sel3, stats=c('elpd', 'rmse'))
# dev.off()
# png("../Image/projpred_sel4_varsel.png")
varsel_plot(sel4, stats=c('elpd', 'rmse'))
# dev.off()
```

まぁ選ばれていないので当然ですが、2変数目ですでにフルモデルにおけるelpdやrmseと接するようになっており、モデルの精度改善に貢献しているのは1変数目だけという結果になっています。

パラメータの分布を見ても、パターン1と比較するといずれも分布の裾が広くなっています。さらにパターン3では正の効果を受けたためか右に裾を引く形とはなっているものの、効果のない他の変数とほとんど変わらない分布となってしまいました。ダミー変数は推定が難しいようです。

```{r}
# png("../Image/projpred_sel2_mcmcarea.png")
mcmc_areas(as.matrix(sel2), 
           pars = names(sel2$varsel$vind[1:5])) + 
   coord_cartesian(xlim = c(-2, 2))
# dev.off()
# png("../Image/projpred_sel3_mcmcarea.png")
mcmc_areas(as.matrix(sel3), 
           pars = names(sel3$varsel$vind[1:5])) + 
   coord_cartesian(xlim = c(-2, 2))
# dev.off()
# png("../Image/projpred_sel4_mcmcarea.png")
mcmc_areas(as.matrix(sel4), 
           pars = names(sel4$varsel$vind[1:5])) + 
   coord_cartesian(xlim = c(-2, 2))
# dev.off()
```

#### 追試
では、ダミー変数が含まれる場合に真のパラメータを捉えることができる確率としてはどの程度になるのでしょうか。パターン3を100回繰り返し、そのうち何回真の変数セットを選択できるか確認してみましょう。


```{r, echo = FALSE}
n  <- 100
t  <- 100
D  <- 20
p0 <- 5
b1 <- 0.5
b2 <- 0.8
tau0 <- p0 / (D-p0) * 1/sqrt(n) 

out <- matrix(0, t, 2)
for (i in 1:t) {
   x <- matrix(rnorm(n * D, 0, 1), nrow = n)
   x[, seq(1, D, 5)] <- ifelse(x[, seq(1, D, 5)] > 0, 1, 0)
   y <- 1.5 + x[, 1] * b1 + x[, 2] * b2 + rnorm(n, 0, 1)
   dat <- data.frame("y" = y, "x" = I(x))
   
   prior_coeff <- hs(global_scale = tau0, slab_scale = 1)
   fit0 <- stan_glm(y ~ x, family = gaussian(), data = dat, prior = prior_coeff,
                    chains = 4, iter = 2000)
   sel0 <- varsel(fit0)
   out[i, ] <-  names(sel0$varsel$vind[1:2])
}
out
```

```{r}
table(out[, 1])
table(out[, 2])
```


上記の通り、連続変数である2列目の選択確率は100%である一方、ダミー変数である1列目は約半数しか選択されないという結果になりました。もちろん回帰係数の大小にも影響されるのでしょうが、結構衝撃的な結果に思えます。


### 終わりに
これまでの実験の結果をまとめると以下のようになりそうです：

 - 連続変数であれば説明変数を20から100に増やしても大きな問題なく変数を選択できそう
 - ダミー変数の変数選択は難しく、今回の条件の場合、半分の確率で失敗する
 - ダミー変数はパラメータの推定も難しい

実際のデータ分析の現場では真のパラメータを予め知ることができないため、変数選択の結果を受け入れざるを得ないことがあるかと思います。しかし今回の実験の結果からは「真の変数セットを選択できる確率は半分程度しかない」ことが示されており、機械的な変数の取捨選択がどれほど危険であるかを教えてくれているのではないでしょうか。

とは言え今回実験に使用した`{projpred}`は便利なlibraryであると思いますので、これから活用しつつも引き続き変数選択の方法について探していこうと思います。
